

import os
from moviepy.editor import VideoFileClip
from faster_whisper import WhisperModel

# 設定資料夾
video_folder = "/video"
audio_folder = "/audio"
transcript_folder = "/output"

# 建立資料夾（如果尚未存在）
os.makedirs(audio_folder, exist_ok=True)
os.makedirs(transcript_folder, exist_ok=True)

# 初始化語音辨識模型
model = WhisperModel("small", device="cpu", compute_type="int8")

# 批次處理影片
for filename in os.listdir(video_folder):
    if filename.lower().endswith(('.mp4', '.mov', '.avi', '.mkv')):
        video_path = os.path.join(video_folder, filename)
        audio_filename = os.path.splitext(filename)[0] + ".wav"
        audio_path = os.path.join(audio_folder, audio_filename)
        transcript_path = os.path.join(transcript_folder, os.path.splitext(filename)[0] + ".txt")

        print(f"[1] 處理影片：{filename}")
        clip = VideoFileClip(video_path)
        clip.audio.write_audiofile(audio_path)

        print(f"[2] 語音辨識中：{audio_filename}")
        segments, info = model.transcribe(audio_path, beam_size=5)

        with open(transcript_path, "w", encoding="utf-8") as f:
            for segment in segments:
                f.write(f"[{segment.start:.2f}s - {segment.end:.2f}s] {segment.text}\n")

        print(f"[3] 完成：{transcript_path}\n")

